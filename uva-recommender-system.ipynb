{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommender Systems: How do they work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommender systems are sociotechnical artefacts which suggests information to a person based on some internal logic. Most systems use (a combination of) two types of logic:\n",
    "- **Collaborative filtering**: recommends based on what people who liked what you liked also liked \n",
    "- **Content filtering**: recommends based on characteristics of the thing you liked that other items also have\n",
    "\n",
    "One way to visualise these two systems is as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/1064/1*mz9tzP1LjPBhmiWXeHyQkQ.png\" alt=\"Recommender systems\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this workshop we'll build a basic version of both of these recommender systems. For this, we will use a dataset that is often used in recommender system tutorials called *MovieLens*: https://www.wikiwand.com/en/MovieLens.\n",
    "The dataset contains a list of movies, rated on a scale of 0-5 by different people, and their genres.\n",
    "\n",
    "We are using this dataset not because it is a particularly interesting subject, but because it gives a window into the culture of data science. In many situations there is a standard dataset, approach, or algorithm that is repeated again and again in online tutorials, demos, workshops, and demos. In many situations, those datasets later turned out to be problematic for various reasons (see e.g., [1], [2]). Knowing what those standard datasets are is helpful when critically studying processes of datafication.\n",
    "\n",
    "\n",
    "[1] Koch et al. (2021) Reduced, Reused and Recycled: The Life of a Dataset in Machine Learning Research. https://openreview.net/pdf?id=zNQBIBKJRkd  \n",
    "[2] Crawford and Paglen. (n.d.) Excavating AI: The Politics of Images in Machine Learning Training Sets https://excavating.ai/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading & exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #import a popular data processing library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first dataset we will look at is the `ratings.csv` file, which contains all the ratings given by users to movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('ratings.csv') #read in the file\n",
    "ratings.head() #show the first 5 items of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of ratings:\", len(ratings))\n",
    "print(\"Number of unique movieId's:\", ratings['movieId'].nunique())\n",
    "print(\"Number of unique users:\", ratings['userId'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.describe() #print out some basic statistics of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second file we are interested in is `movies.csv`, which contains movie titles and the genres that someone has decided they belong to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('movies.csv')\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because both files have a similar column `movieId`, we can easily merge them and get one dataset that has ratings by users, movie titles, and movie genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.merge(ratings, movies, on='movieId') #merge `ratings` and `movies` on the values in column `movieId`\n",
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.sort_values('rating', ascending=False) #sort the data from highest rating to lowest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data imported and we have a basic sense of what is in there, we can start working with it to create our two recommendation algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collaborative filtering means that you get recommended something based on what other people liked, but only from people who also liked something you've liked in the past.\n",
    "\n",
    "\n",
    "To do this, we need to transform our data structure into something called a user-by-item matrix, which is a fancy way of saying a table with item ratings, where the rows are different users and the columns are the different items. For us, this means the columns are the movies, the rows are the people, and in each cell is the rating between 0-5 that a person gave to that particular movie.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new table with the rows being userIds, the columns being the movie title, and \n",
    "#the values in the cells the rating\n",
    "movie_matrix = merged_data.pivot_table(index='userId', columns='title', values='rating')\n",
    "\n",
    "#Not every user has rated every movie, but we can't just leave that empty.\n",
    "#So we fill in all the na ('no answer') with 0s, so that everything in our table is numbers, and we can do math with it.\n",
    "movie_matrix = movie_matrix.fillna(0) \n",
    "movie_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data in a structure that we like, we can start recommending things! The way we do this is by trying to find a movies whose ratings are very similar, i.e. strongly correlated. For this we will calculate Pearson's correlation coefficient* between the different columns. This will give us a score between -1 (not at all similar) to 1 (very similar)\n",
    "<br><br>\n",
    "  \n",
    "\n",
    "\n",
    "\\* technically Spearman's Rank Order Correlation is better for ordinal data, but it is a less intuitive score and given the size of our dataset it does not have that big of an impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The movie we liked and based on which we want to find recommendations\n",
    "movie = 'Lion King, The (1994)'\n",
    "\n",
    "#Calculate the correlation\n",
    "collaborative_recommendation = movie_matrix.corrwith(movie_matrix[movie])\n",
    "\n",
    "#Sort the results from highest to lowest correlation score\n",
    "collaborative_recommendation = collaborative_recommendation.sort_values(ascending=False)\n",
    "\n",
    "#Make the table look pretty and print the top 10\n",
    "pd.DataFrame(collaborative_recommendation, columns=['corr']).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to work pretty well!\n",
    "However, collaborative filtering approaches have one big weakness: it can't recommend items that don't have any scores and it can't recommend anything to someone who hasn't scored anything! \n",
    "This is also referred to as the **cold start problem**: no inferences are possible for something we don't have any information about.  \n",
    "\n",
    "One way to fix the cold start problem is to use something called content filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Content filtering means that you get recommended something that is similar to what you liked before, and that similarity is often based on some internal characteristics that someone else decided items have. In our carse, the genres that movies fall into.\n",
    "\n",
    "Let's look at our data again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, each movie has a list of genres, separated by `|`. For us to work with this data, we have to transform it again into a different structure. First, we have to split the genres and put them into a list (a formal Python data structure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['genres'] = movies['genres'].str.split('|') #split the string data in the column `genres`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head() #show the first five items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to, again, create a type of matrix, with the movies as columns, the genres as rows, and in each cell either a 0 and a 1 to indicate whether this movie belongs in this genre (1) or not (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, let's set the row names to be the same as the movie titles, \n",
    "#so it will be easier to figure out which score belongs to which movie later\n",
    "movies = movies.set_index('title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now `explode` the list of genres so that each genre has their own column.\n",
    "#Next, sum all rows of the same movie, such that there is only one row per movie with the binary genre score\n",
    "#then transpose (i.e. flip) the table to get the movies at the top\n",
    "movie_features = pd.get_dummies(movies['genres'].explode()).sum(level=0).transpose()\n",
    "movie_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The movie we liked and based on which we want to find recommendations\n",
    "movie = 'Lion King, The (1994)'\n",
    "\n",
    "#Calculate the correlation\n",
    "content_recommendation = movie_features.corrwith(movie_features[movie])\n",
    "\n",
    "#Sort the results from highest to lowest correlation score\n",
    "content_recommendation = content_recommendation.sort_values(ascending=False)\n",
    "\n",
    "#Make the table look pretty and print the top 10\n",
    "pd.DataFrame(content_recommendation, columns=['corr']).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, these two logics do not give the same recommendations. While content filtering overcomes the cold start problem of a collaborative approach, it has its own limitations. First, you need labels for each item to describe what it is, and if those labels are not granular enough (e.g., only 20 genres), differences that matter to people might not be captured. Second, by only recommending things with the same characteristics, people might get trapped into a 'rabbit hole' or 'echo chamber', and are no longer exposed to diverse information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
